{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skmultilearn\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "import logging\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>/m/025zzc</th>\n",
       "      <th>/m/02ntfj</th>\n",
       "      <th>/m/0b1vjn</th>\n",
       "      <th>/m/02hygl</th>\n",
       "      <th>/m/04q1x3q</th>\n",
       "      <th>/m/01sjng</th>\n",
       "      <th>/m/0403l3g</th>\n",
       "      <th>/m/021bp2</th>\n",
       "      <th>/m/022dc6</th>\n",
       "      <th>/m/03hf_rm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UC-Zedn7a_RJyb5hUQ-aGZog</th>\n",
       "      <td>서양권 인물의 성씨로 쓰인다 자세한 내용은 머독인터넷 방송인 문서를의 번째 문단을의...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC1dG3vI9FfHnH3YgyeKUz_A</th>\n",
       "      <td>말부터 시작한 아프리카tv의 리그 오브 레전드 bj 챌린저 정글러다 콘텐츠로 강의방...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC1MO5uem_t8lRgvIBF9u83w</th>\n",
       "      <td>게임 영상 투고 및 게임 번역을 주로 하는 유튜버ai설이 나돌 정도로 과묵하고 묵묵...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC1q4Ihlv_YhLELw-ijE0Diw</th>\n",
       "      <td>마인크래프트를 주로 하는 팀 샐러드 소속의 유튜버이자 트위치 스트리머마인애플은 마인...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC2FDVyrQnjoZCUyk9fmqd9g</th>\n",
       "      <td>중순부터 본격적으로 방송을 시작한 크로아티아 출신 인터넷 방송인 일명 푸른 눈의 팟...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     review  \\\n",
       "UC-Zedn7a_RJyb5hUQ-aGZog  서양권 인물의 성씨로 쓰인다 자세한 내용은 머독인터넷 방송인 문서를의 번째 문단을의...   \n",
       "UC1dG3vI9FfHnH3YgyeKUz_A  말부터 시작한 아프리카tv의 리그 오브 레전드 bj 챌린저 정글러다 콘텐츠로 강의방...   \n",
       "UC1MO5uem_t8lRgvIBF9u83w  게임 영상 투고 및 게임 번역을 주로 하는 유튜버ai설이 나돌 정도로 과묵하고 묵묵...   \n",
       "UC1q4Ihlv_YhLELw-ijE0Diw  마인크래프트를 주로 하는 팀 샐러드 소속의 유튜버이자 트위치 스트리머마인애플은 마인...   \n",
       "UC2FDVyrQnjoZCUyk9fmqd9g  중순부터 본격적으로 방송을 시작한 크로아티아 출신 인터넷 방송인 일명 푸른 눈의 팟...   \n",
       "\n",
       "                          /m/025zzc  /m/02ntfj  /m/0b1vjn  /m/02hygl  \\\n",
       "UC-Zedn7a_RJyb5hUQ-aGZog       True      False      False      False   \n",
       "UC1dG3vI9FfHnH3YgyeKUz_A       True      False      False      False   \n",
       "UC1MO5uem_t8lRgvIBF9u83w       True       True      False      False   \n",
       "UC1q4Ihlv_YhLELw-ijE0Diw       True      False      False      False   \n",
       "UC2FDVyrQnjoZCUyk9fmqd9g       True      False      False      False   \n",
       "\n",
       "                          /m/04q1x3q  /m/01sjng  /m/0403l3g  /m/021bp2  \\\n",
       "UC-Zedn7a_RJyb5hUQ-aGZog       False      False        True      False   \n",
       "UC1dG3vI9FfHnH3YgyeKUz_A       False      False        True      False   \n",
       "UC1MO5uem_t8lRgvIBF9u83w       False      False        True      False   \n",
       "UC1q4Ihlv_YhLELw-ijE0Diw       False      False        True      False   \n",
       "UC2FDVyrQnjoZCUyk9fmqd9g       False      False       False      False   \n",
       "\n",
       "                          /m/022dc6  /m/03hf_rm  \n",
       "UC-Zedn7a_RJyb5hUQ-aGZog      False       False  \n",
       "UC1dG3vI9FfHnH3YgyeKUz_A      False       False  \n",
       "UC1MO5uem_t8lRgvIBF9u83w      False       False  \n",
       "UC1q4Ihlv_YhLELw-ijE0Diw      False       False  \n",
       "UC2FDVyrQnjoZCUyk9fmqd9g      False       False  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_IN_PATH = os.getcwd() + '\\\\crawling_result\\\\youtuber_text'\n",
    "CRAWLER_PATH = os.getcwd() + '\\\\crawling_result'\n",
    "\n",
    "train_data = pd.read_csv(CRAWLER_PATH + '\\\\train_data.csv',index_col=0, engine='python', encoding = \"utf-8\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = list(train_data['review'])\n",
    "train_labels = train_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 0.0, analyzer='char', sublinear_tf=True, ngram_range=(1,3), max_features=10)\n",
    "X = tfidf.fit_transform(train_text)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 05:16:39,722 : INFO : collecting all words and their counts\n",
      "2020-12-21 05:16:39,728 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-21 05:16:39,847 : INFO : collected 97499 word types from a corpus of 322129 raw words and 100 sentences\n",
      "2020-12-21 05:16:39,847 : INFO : Loading a fresh vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 05:16:39,908 : INFO : effective_min_count=40 retains 935 unique words (0% of original 97499, drops 96564)\n",
      "2020-12-21 05:16:39,909 : INFO : effective_min_count=40 leaves 111112 word corpus (34% of original 322129, drops 211017)\n",
      "2020-12-21 05:16:39,911 : INFO : deleting the raw counts dictionary of 97499 items\n",
      "2020-12-21 05:16:39,917 : INFO : sample=0.001 downsamples 63 most-common words\n",
      "2020-12-21 05:16:39,923 : INFO : downsampling leaves estimated 97523 word corpus (87.8% of prior 111112)\n",
      "2020-12-21 05:16:39,927 : INFO : estimated required memory for 935 words and 300 dimensions: 2711500 bytes\n",
      "2020-12-21 05:16:39,928 : INFO : resetting layer weights\n",
      "2020-12-21 05:16:40,126 : INFO : training model with 4 workers on 935 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-12-21 05:16:40,229 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-21 05:16:40,230 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-21 05:16:40,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-21 05:16:40,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-21 05:16:40,241 : INFO : EPOCH - 1 : training on 322129 raw words (97601 effective words) took 0.1s, 885249 effective words/s\n",
      "2020-12-21 05:16:40,374 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-21 05:16:40,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-21 05:16:40,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-21 05:16:40,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-21 05:16:40,388 : INFO : EPOCH - 2 : training on 322129 raw words (97540 effective words) took 0.1s, 736198 effective words/s\n",
      "2020-12-21 05:16:40,526 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-21 05:16:40,528 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-21 05:16:40,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-21 05:16:40,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-21 05:16:40,530 : INFO : EPOCH - 3 : training on 322129 raw words (97542 effective words) took 0.1s, 707648 effective words/s\n",
      "2020-12-21 05:16:40,642 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-21 05:16:40,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-21 05:16:40,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-21 05:16:40,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-21 05:16:40,654 : INFO : EPOCH - 4 : training on 322129 raw words (97439 effective words) took 0.1s, 801567 effective words/s\n",
      "2020-12-21 05:16:40,814 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-21 05:16:40,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-21 05:16:40,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-21 05:16:40,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-21 05:16:40,878 : INFO : EPOCH - 5 : training on 322129 raw words (97349 effective words) took 0.2s, 451969 effective words/s\n",
      "2020-12-21 05:16:40,879 : INFO : training on a 1610645 raw words (487471 effective words) took 0.8s, 647991 effective words/s\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for t in train_text:\n",
    "    sentences.append(t.split())\n",
    "\n",
    "labels = train_labels.values\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count= min_word_count, window=context, sample=downsampling )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 05:17:26,198 : INFO : saving Word2Vec object under 300features_40minwords10context, separately None\n",
      "2020-12-21 05:17:26,199 : INFO : not storing attribute vectors_norm\n",
      "2020-12-21 05:17:26,202 : INFO : not storing attribute cum_table\n",
      "2020-12-21 05:17:26,226 : INFO : saved 300features_40minwords10context\n"
     ]
    }
   ],
   "source": [
    "model_name = \"300features_40minwords10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    \n",
    "    num_words = 0\n",
    "    \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "            \n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "    \n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "        \n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-456-a665bc594b10>:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  feature_vector = np.add(feature_vector, model[w])\n"
     ]
    }
   ],
   "source": [
    "X = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02854413, -0.13910031, -0.10310345, ...,  0.02278697,\n",
       "        -0.10987526, -0.04159285],\n",
       "       [-0.01004763, -0.0394398 ,  0.01493916, ...,  0.08809038,\n",
       "        -0.10209024, -0.02917306],\n",
       "       [-0.04095584, -0.03055699,  0.01647139, ...,  0.10322094,\n",
       "        -0.12138531, -0.02858691],\n",
       "       ...,\n",
       "       [-0.04654637, -0.01385875,  0.00698293, ...,  0.09984439,\n",
       "        -0.12048138, -0.02880032],\n",
       "       [ 0.03087607, -0.12843002, -0.07048663, ...,  0.06692038,\n",
       "        -0.3457006 , -0.01524172],\n",
       "       [-0.05248855,  0.01018768, -0.01950465, ...,  0.08926157,\n",
       "        -0.13405801, -0.0255207 ]], dtype=float32)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "y = train_labels\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model, mlb_estimator, xtrain, ytrain, xtest, ytest):\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    clf_predictions = clf.predict(xtest)\n",
    "    print(clf_predictions.toarray())\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    ham = hamming_loss(ytest, clf_predictions)\n",
    "    result = {\"accuracy\": acc, \"hamming score\": ham}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True False False False False False False False False]\n",
      " [ True  True  True False False False False False False  True]\n",
      " [ True  True  True False False False False False False  True]\n",
      " [ True False  True False False False  True False False False]\n",
      " [ True  True  True False False  True False False False  True]\n",
      " [ True  True  True False False False False False False  True]\n",
      " [False False False False False False  True False False False]\n",
      " [ True  True  True False False  True False False False  True]\n",
      " [ True  True  True False False  True False False False  True]\n",
      " [ True False False False False False  True False False False]\n",
      " [ True  True  True False False  True False False False  True]\n",
      " [ True False False False False  True  True False False  True]\n",
      " [ True False False False False False  True False False False]\n",
      " [ True  True  True False False False False False False False]\n",
      " [ True False False False False False  True False False  True]\n",
      " [ True  True False False False False False False False False]\n",
      " [ True False  True False False False  True False False False]\n",
      " [False False False False False False  True False False False]\n",
      " [ True False  True False False False  True False False False]\n",
      " [ True False False False False False  True False False False]]\n"
     ]
    }
   ],
   "source": [
    "clf_binary_model = build_model(GaussianNB(), BinaryRelevance, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.2, 'hamming score': 0.215}"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "clf_chain_model = build_model(GaussianNB(), ClassifierChain, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.15, 'hamming score': 0.115}"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_chain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 1]\n",
      " [1 1 0 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# LabelPowerset\n",
    "clf_labelP_model = build_model(GaussianNB(), LabelPowerset, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.25, 'hamming score': 0.125}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_labelP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

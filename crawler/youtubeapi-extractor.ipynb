{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "scrapingenv1",
   "display_name": "scrapingEnv1",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 유튜브 api 크롤링 결과 분석기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 결과 가져오기\n",
    "\n",
    "f = open('./crawling_result_text/testerhoon2.txt', mode='rt', encoding='utf-8')\n",
    "\n",
    "strings = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 활용 말뭉치 정리\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "stop_special_char = re.sub(pattern='[가-힣 a-zA-Z\\d\\.\\n]+', repl='', string=strings)\n",
    "stop_special_char_pattern = '[' + '\\\\'.join(set(stop_special_char)) + ']'\n",
    "\n",
    "print(stop_special_char_pattern)\n",
    "\n",
    "new_strings = re.sub(pattern=stop_special_char_pattern, repl='',string=strings)\n",
    "new_strings = re.sub(pattern='\\s{2,}',repl=' ',string=new_strings)\n",
    "new_strings = re.sub(pattern='[\\n]+',repl=' ',string=new_strings)\n",
    "new_strings = re.sub(pattern='[a-zA-Z\\,]+',repl='',string=new_strings)\n",
    "new_strings = re.sub(pattern='[0-9]+', repl='', string=new_strings)\n",
    "new_strings = re.sub(pattern='\\s{2,}',repl=' ',string=new_strings)\n",
    "new_strings = re.sub(pattern='롤', repl='리그오브레전드', string=new_strings)\n",
    "new_strings = re.sub(pattern='아프리카', repl='아프리카티비', string=new_strings)\n",
    "new_strings = re.sub(pattern='아프리카티비티비', repl='아프리카티비', string=new_strings)\n",
    "# new_strings = [ line.strip() for line in new_strings.split('.') if len(line) > 4 ]\n",
    "print(new_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#품사 태깅\n",
    "\n",
    "from konlpy.tag import Hannanum\n",
    "\n",
    "hannanum = Hannanum()\n",
    "\n",
    "print(hannanum.nouns(new_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어사전(자체 제작)\n",
    "stopwords = ['라', '중', '이', '때문', '지', '이상', '등', '수', '것', '시작', '부분', '당시', '경우', '이후', '오브', '리그', '편', '위', '정도', '활동', '전', \n",
    "    '한', '도중', '자체', '경기', '방송이','때','녹두','이유','문단을','대부분','번','일','리','두','초','나','문단','문','방송','적','후','단어','게임','유튜브','영상','말','역사','시청자들','본인','이전','시청자','2020년','2018년','2019년','2017년','2016년','업로드','콘텐츠','듯','현재','명','들','사람','1','개','관련','채널','모습','주','거','내','사이','자신','유튜버','컨텐츠','생각'] +['1월','2월','3월','4월','5월','6월','7월','8월','9월','10월','11월','12월'] + ['감스트', '비감', '인직'] + ['진짜'] + ['아', '휴', '아이구', '아이쿠', '아이고','어','나','우리','저희','따라','의해','을','를','에','의','가','으로','로','에게','뿐이다','저','지말고','다','뿐','허','헉','곧','이다','도','부터','모','등','조금','좀','대','종','망','그','데','에','애','제','장']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드 클라우드 생성\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Twitter\n",
    "import pytagcloud\n",
    "import webbrowser\n",
    "\n",
    "r = lambda: random.randint(0,255)\n",
    "color = lambda: (r(),r(),r())\n",
    "\n",
    "def get_tags(text, ntags=100, multiplier=10):\n",
    "    h = Hannanum()\n",
    "    nouns = h.nouns(text)\n",
    "    unique_nouns = set(nouns)\n",
    "    for word in unique_nouns:\n",
    "        if word in stopwords:\n",
    "            while word in nouns:\n",
    "                nouns.remove(word)\n",
    "\n",
    "    count = Counter(nouns)\n",
    "    print(count)\n",
    "    return [{ 'color': color(), 'tag': n, 'size': int(math.sqrt(c)*multiplier) }\\\n",
    "                for n, c in count.most_common(ntags)]\n",
    "\n",
    "\n",
    "\n",
    "def get_tags_twitter(text, ntags=100, multiplier=5):\n",
    "    t =Twitter()\n",
    "    nouns = t.nouns(text)\n",
    "    unique_nouns = set(nouns)\n",
    "    for word in unique_nouns:\n",
    "        if word in stopwords:\n",
    "            while word in nouns:\n",
    "                nouns.remove(word)\n",
    "\n",
    "    count = Counter(nouns)\n",
    "    return [{ 'color': color(), 'tag': n, 'size': int(c*multiplier) }\\\n",
    "                for n, c in count.most_common(ntags)]\n",
    "\n",
    "\n",
    "def draw_cloud(tags, filename, fontname='Korean', size=(1600, 1200)):\n",
    "    pytagcloud.create_tag_image(tags, filename, fontname=fontname, size=size)\n",
    "    webbrowser.open( os.path.relpath(filename) )\n",
    "\n",
    "\n",
    "tags = get_tags(new_strings)\n",
    "print(tags)\n",
    "draw_cloud(tags,'./crawling_result_wordcloud/WC_You_testerhoon2.png')\n"
   ]
  }
 ]
}